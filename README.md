# ü§ñ LM Studio Docker para EasyPanel

Configuraci√≥n completa de LM Studio en Docker optimizada para CPU y EasyPanel.

## üìã Descripci√≥n

Este proyecto proporciona una configuraci√≥n completa para ejecutar LM Studio en un contenedor Docker, optimizado para funcionar solo con CPU en Ubuntu 24.04 y desplegado a trav√©s de EasyPanel.

## üöÄ Caracter√≠sticas

- ‚úÖ **Optimizado para CPU**: Sin dependencias de GPU
- ‚úÖ **Interfaz Web**: Acceso a trav√©s de noVNC en el navegador
- ‚úÖ **API REST**: Compatible con OpenAI API
- ‚úÖ **Descarga autom√°tica**: Modelos populares se descargan autom√°ticamente
- ‚úÖ **EasyPanel Ready**: Configuraci√≥n espec√≠fica para EasyPanel
- ‚úÖ **Vol√∫menes persistentes**: Modelos y configuraci√≥n se mantienen
- ‚úÖ **Monitoreo**: Logs y healthchecks incluidos

## üìÅ Archivos Incluidos

- `Dockerfile` - Imagen Docker optimizada para CPU
- `docker-compose.yml` - Configuraci√≥n de servicios y vol√∫menes
- `supervisord.conf` - Gesti√≥n de procesos internos
- `start.sh` - Script de inicio del contenedor
- `download-models.sh` - Descarga autom√°tica de modelos
- `.env` - Variables de entorno configurables
- `EASYPANEL-SETUP.md` - Configuraci√≥n espec√≠fica de EasyPanel
- `INSTRUCCIONES-PASO-A-PASO.md` - Gu√≠a completa de instalaci√≥n

## üîß Requisitos del Sistema

### M√≠nimos
- **CPU**: 4 cores
- **RAM**: 8GB
- **Almacenamiento**: 100GB
- **OS**: Ubuntu 24.04

### Recomendados
- **CPU**: 8+ cores
- **RAM**: 16GB+
- **Almacenamiento**: 200GB+
- **Red**: Conexi√≥n estable para descarga de modelos

## üöÄ Inicio R√°pido

### 1. Preparar archivos
```bash
git clone <este-repositorio>
cd DockerLM
chmod +x start.sh download-models.sh
```

### 2. Crear vol√∫menes en EasyPanel
- `lmstudio_models` (100GB)
- `lmstudio_cache` (20GB)  
- `lmstudio_logs` (5GB)

### 3. Desplegar en EasyPanel
1. Crear nueva aplicaci√≥n Docker Compose
2. Copiar contenido de `docker-compose.yml`
3. Configurar variables de entorno desde `.env`
4. Configurar puertos: 1234, 6080, 5900
5. Desplegar

### 4. Acceder
- **Interfaz Web**: `http://tu-servidor:6080`
- **API**: `http://tu-servidor:1234`
- **Contrase√±a VNC**: `lmstudio`

## üìä Puertos Expuestos

| Puerto | Servicio | Descripci√≥n |
|--------|----------|-------------|
| 1234 | LM Studio API | API REST compatible con OpenAI |
| 6080 | noVNC Web | Interfaz web para acceso remoto |
| 5900 | VNC Directo | Conexi√≥n VNC directa |

## üóÇÔ∏è Vol√∫menes

| Volumen | Ruta | Prop√≥sito |
|---------|------|-----------|
| `lmstudio_models` | `/home/lmstudio/models` | Modelos de IA descargados |
| `lmstudio_cache` | `/home/lmstudio/.cache/lm-studio` | Cache de LM Studio |
| `lmstudio_logs` | `/home/lmstudio/logs` | Archivos de log |

## ü§ñ Modelos Incluidos

Se descargan autom√°ticamente al iniciar:

- **Llama 3.2 1B Instruct** (~1GB) - Muy r√°pido
- **Llama 3.2 3B Instruct** (~2GB) - Equilibrado  
- **Phi-3 Mini 4K** (~2.5GB) - Eficiente para CPU
- **Gemma 2B Instruct** (~1.5GB) - Ligero de Google
- **Qwen 2.5 1.5B** (~1GB) - Muy eficiente

## üîß Configuraci√≥n

### Variables de Entorno Principales
```env
LMSTUDIO_API_PORT=1234
NOVNC_WEB_PORT=6080
VNC_DIRECT_PORT=5900
MEMORY_LIMIT=8G
LMSTUDIO_HOST=0.0.0.0
AUTO_DOWNLOAD_MODELS=true
```

### Optimizaci√≥n para CPU
- Configuraci√≥n autom√°tica para uso exclusivo de CPU
- Sin dependencias de CUDA o GPU
- Optimizado para modelos cuantizados (GGUF)

## üìñ Documentaci√≥n Detallada

- **[Configuraci√≥n EasyPanel](EASYPANEL-SETUP.md)** - Configuraci√≥n espec√≠fica de vol√∫menes y aplicaci√≥n
- **[Instrucciones Paso a Paso](INSTRUCCIONES-PASO-A-PASO.md)** - Gu√≠a completa de instalaci√≥n
- **[Variables de Entorno](.env)** - Configuraci√≥n personalizable

## üîç API Usage

### Listar modelos disponibles
```bash
curl http://localhost:1234/v1/models
```

### Chat completion
```bash
curl -X POST http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.2-1b-instruct",
    "messages": [{"role": "user", "content": "Hola"}],
    "temperature": 0.7
  }'
```

## üÜò Troubleshooting

### Contenedor no inicia
```bash
docker logs lmstudio-app
```

### Verificar vol√∫menes
```bash
docker volume ls | grep lmstudio
```

### Verificar recursos
- Monitorea CPU y RAM en EasyPanel
- Verifica espacio en disco disponible
- Revisa logs de la aplicaci√≥n

## üîí Seguridad

- Cambia la contrase√±a VNC por defecto
- Configura firewall apropiadamente
- Usa HTTPS para acceso externo
- Considera autenticaci√≥n adicional para producci√≥n

## üìù Notas Importantes

- ‚ö†Ô∏è **Solo CPU**: Esta configuraci√≥n NO usa GPU
- ‚ö†Ô∏è **Descarga autom√°tica**: Los modelos se descargan al iniciar (puede tomar tiempo)
- ‚ö†Ô∏è **Recursos**: Aseg√∫rate de tener suficiente RAM y CPU
- ‚ö†Ô∏è **Vol√∫menes**: DEBEN crearse manualmente en EasyPanel antes del despliegue

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver `LICENSE` para m√°s detalles.

## üôè Agradecimientos

- [LM Studio](https://lmstudio.ai/) por la excelente aplicaci√≥n
- [EasyPanel](https://easypanel.io/) por la plataforma de despliegue
- Comunidad de modelos de Hugging Face

---

**¬øNecesitas ayuda?** Revisa las [Instrucciones Paso a Paso](INSTRUCCIONES-PASO-A-PASO.md) o abre un issue.