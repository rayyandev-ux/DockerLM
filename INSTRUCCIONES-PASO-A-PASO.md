# üöÄ Instrucciones Paso a Paso: LM Studio en EasyPanel

## üìã Requisitos Previos

- ‚úÖ Acceso a EasyPanel
- ‚úÖ Ubuntu 24.04 como sistema base
- ‚úÖ Docker instalado en EasyPanel
- ‚úÖ Al menos 8GB RAM y 4 CPU cores disponibles
- ‚úÖ 100GB de espacio en disco disponible

## üîß PASO 1: Preparar los Archivos

### 1.1 Subir archivos a tu servidor
Sube todos los archivos de este proyecto a tu servidor:
- `Dockerfile`
- `docker-compose.yml`
- `supervisord.conf`
- `start.sh`
- `download-models.sh`
- `.env`

### 1.2 Dar permisos de ejecuci√≥n
```bash
chmod +x start.sh download-models.sh
```

## üóÑÔ∏è PASO 2: Crear Vol√∫menes en EasyPanel

### 2.1 Acceder a EasyPanel
1. Inicia sesi√≥n en tu panel de EasyPanel
2. Ve a la secci√≥n "Volumes" o "Vol√∫menes"

### 2.2 Crear volumen para modelos
1. Clic en "Create Volume"
2. **Nombre**: `lmstudio_models`
3. **Tama√±o**: 100GB (recomendado)
4. **Descripci√≥n**: "Modelos de IA para LM Studio"
5. Clic en "Create"

### 2.3 Crear volumen para cache
1. Clic en "Create Volume"
2. **Nombre**: `lmstudio_cache`
3. **Tama√±o**: 20GB
4. **Descripci√≥n**: "Cache de LM Studio"
5. Clic en "Create"

### 2.4 Crear volumen para logs
1. Clic en "Create Volume"
2. **Nombre**: `lmstudio_logs`
3. **Tama√±o**: 5GB
4. **Descripci√≥n**: "Logs de LM Studio"
5. Clic en "Create"

## üê≥ PASO 3: Crear la Aplicaci√≥n en EasyPanel

### 3.1 Nueva aplicaci√≥n
1. Ve a "Applications" en EasyPanel
2. Clic en "Create Application"
3. Selecciona "Docker Compose"
4. **Nombre**: `lmstudio`
5. **Descripci√≥n**: "LM Studio - Local AI Models"

### 3.2 Configurar Docker Compose
1. En el editor, pega el contenido completo del archivo `docker-compose.yml`
2. Verifica que los nombres de vol√∫menes coincidan con los creados anteriormente

### 3.3 Configurar variables de entorno
En la secci√≥n "Environment Variables", agrega:

```
LMSTUDIO_API_PORT=1234
NOVNC_WEB_PORT=6080
VNC_DIRECT_PORT=5900
MEMORY_LIMIT=8G
MEMORY_RESERVATION=4G
LMSTUDIO_HOST=0.0.0.0
LMSTUDIO_MODELS_PATH=/home/lmstudio/models
LMSTUDIO_CACHE_PATH=/home/lmstudio/.cache/lm-studio
VNC_PASSWORD=lmstudio
DISPLAY=:1
AUTO_DOWNLOAD_MODELS=true
LOG_LEVEL=INFO
```

## üåê PASO 4: Configurar Puertos y Dominios

### 4.1 Configurar puertos
En la secci√≥n "Ports", agrega:

1. **Puerto 1234**:
   - Protocolo: HTTP
   - Descripci√≥n: "API de LM Studio"

2. **Puerto 6080**:
   - Protocolo: HTTP
   - Descripci√≥n: "Interfaz Web noVNC"

3. **Puerto 5900**:
   - Protocolo: TCP
   - Descripci√≥n: "VNC Directo"

### 4.2 Configurar dominios (opcional)
Si quieres acceso externo:

1. **Para la interfaz web**:
   - Dominio: `lmstudio.tudominio.com`
   - Puerto: 6080
   - SSL: Recomendado

2. **Para la API**:
   - Dominio: `lmstudio-api.tudominio.com`
   - Puerto: 1234
   - SSL: Recomendado

## üöÄ PASO 5: Desplegar la Aplicaci√≥n

### 5.1 Iniciar despliegue
1. Revisa toda la configuraci√≥n
2. Clic en "Deploy" o "Desplegar"
3. Espera a que se complete la construcci√≥n de la imagen (puede tomar 10-15 minutos)

### 5.2 Monitorear el despliegue
1. Ve a la secci√≥n "Logs" de la aplicaci√≥n
2. Verifica que no hay errores
3. Busca el mensaje "‚úÖ Script completado exitosamente"

## üì• PASO 6: Descargar Modelos (Autom√°tico)

### 6.1 Verificar descarga autom√°tica
Los modelos se descargan autom√°ticamente al iniciar. Puedes verificar:

1. Ve a los logs de la aplicaci√≥n
2. Busca mensajes como "Descargando Llama 3.2 1B..."
3. La descarga puede tomar 30-60 minutos dependiendo de tu conexi√≥n

### 6.2 Modelos incluidos autom√°ticamente
- **Llama 3.2 1B Instruct** (~1GB) - Muy r√°pido
- **Llama 3.2 3B Instruct** (~2GB) - Equilibrado
- **Phi-3 Mini 4K** (~2.5GB) - Eficiente
- **Gemma 2B Instruct** (~1.5GB) - Ligero
- **Qwen 2.5 1.5B** (~1GB) - Muy eficiente

## üîç PASO 7: Verificar la Instalaci√≥n

### 7.1 Acceder a la interfaz web
1. Ve a `http://tu-servidor:6080` (o tu dominio configurado)
2. Deber√≠as ver la interfaz de noVNC
3. Clic en "Connect"
4. Contrase√±a: `lmstudio`

### 7.2 Verificar LM Studio
1. Dentro de la interfaz, deber√≠as ver LM Studio ejecut√°ndose
2. Ve a la pesta√±a "Models" para ver los modelos descargados
3. Prueba cargar un modelo peque√±o como Llama 3.2 1B

### 7.3 Probar la API
```bash
# Verificar modelos disponibles
curl http://tu-servidor:1234/v1/models

# Probar chat (despu√©s de cargar un modelo)
curl -X POST http://tu-servidor:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama-3.2-1b-instruct",
    "messages": [{"role": "user", "content": "Hola, ¬øc√≥mo est√°s?"}],
    "temperature": 0.7
  }'
```

## üîß PASO 8: Configuraci√≥n Adicional

### 8.1 Optimizar para CPU
En LM Studio (interfaz web):
1. Ve a Settings ‚Üí Performance
2. Configura "CPU Threads" al n√∫mero de cores disponibles
3. Desactiva "GPU Acceleration"
4. Ajusta "Context Length" seg√∫n tu RAM

### 8.2 Configurar modelos
1. En la pesta√±a "Models", carga un modelo peque√±o primero
2. Ajusta los par√°metros seg√∫n tu hardware:
   - **4GB RAM**: Usa modelos 1B
   - **8GB RAM**: Usa modelos 1B-3B
   - **16GB+ RAM**: Usa modelos 3B-7B

## üìä PASO 9: Monitoreo y Mantenimiento

### 9.1 Verificar recursos
En EasyPanel:
1. Monitorea uso de CPU y RAM
2. Verifica espacio en vol√∫menes
3. Revisa logs regularmente

### 9.2 Backup de modelos
Los modelos est√°n en el volumen `lmstudio_models`. Considera:
1. Backup regular del volumen
2. Documentar qu√© modelos tienes instalados
3. Mantener espacio libre para nuevos modelos

## üÜò Troubleshooting Com√∫n

### Problema: Contenedor no inicia
```bash
# Verificar logs
docker logs lmstudio-app

# Verificar vol√∫menes
docker volume ls | grep lmstudio
```

### Problema: No se puede acceder a la interfaz
1. Verifica que el puerto 6080 est√© abierto
2. Comprueba firewall del servidor
3. Revisa logs de noVNC

### Problema: Modelos no se descargan
1. Verifica conexi√≥n a internet
2. Comprueba espacio en disco
3. Revisa permisos de vol√∫menes

### Problema: Rendimiento lento
1. Aumenta CPU cores en EasyPanel
2. Incrementa RAM asignada
3. Usa modelos m√°s peque√±os
4. Verifica que no hay otros procesos pesados

## ‚úÖ Verificaci√≥n Final

Despu√©s de completar todos los pasos:

- [ ] Contenedor ejecut√°ndose sin errores
- [ ] Interfaz web accesible en puerto 6080
- [ ] API respondiendo en puerto 1234
- [ ] Al menos un modelo descargado y funcional
- [ ] Logs sin errores cr√≠ticos
- [ ] Recursos del sistema estables

## üéâ ¬°Listo!

Tu instalaci√≥n de LM Studio est√° completa. Ahora puedes:

1. **Usar la interfaz web**: `http://tu-servidor:6080`
2. **Usar la API**: `http://tu-servidor:1234`
3. **Descargar m√°s modelos** desde la interfaz
4. **Integrar con aplicaciones** usando la API REST

## üìö Recursos Adicionales

- **Documentaci√≥n de LM Studio**: https://lmstudio.ai/docs
- **Modelos recomendados**: Hugging Face GGUF models
- **API Reference**: `http://tu-servidor:1234/docs`

¬°Disfruta usando LM Studio en tu servidor! üöÄ